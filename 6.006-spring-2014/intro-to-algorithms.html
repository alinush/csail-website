<html>
	<head>
		<title>Alin Tomescu | CSG | CSAIL | MIT | 6.006 Intro to Algorithms | Spring 2014</title>
	</head>

<body>

<h1>6.006 Intro to Algorithms: Extra Materials</h1>

<p>A <big><b>big</b></big> <em>"thank you"</em> to my students for submitting their evaluations and for their great feedback :)</p>
<p>The materials I posted for my two 6.006 recitations in Spring 2014 can be found below.</p>

<h3>"Prependix"</h3>
<ul>
	<li><strong>Fun, fun:</strong> <a href="http://web.eecs.umich.edu/~bnoble/482/handouts/lectures.txt">Why you should "grind" on algorithms and ask questions in recitation...</a></li>
	<li>
		Textbooks: 
		<ul>
			<li><a href="https://mitpress.mit.edu/books/introduction-algorithms">Introduction to Algorithms</a>, 3rd edition, by Cormen, Leiserson, Rivest & Stein</li>
			<li><a href="http://www.cs.sunysb.edu/~algorith/">The Algorithm Design Manual</a>, 2nd edition, by Steven Skiena</li>
			<li><a href="http://www.cs.berkeley.edu/~vazirani/algorithms/">Algorithms</a>, by Dasgupta, Papadimitriou & Vazirani</li>
		</ul>
	</li>
</ul>

<h3>Lecture 1: Asymptotic complexity, recurrences, peak finding</h3>
<ul>
	<li><a href="2014.02.04.w01.tu-overview-peak-finding-lec01.pdf">Lecture 1 notes</a>, from Tuesday, February 4th, Week 1
	<li><a href="n-choose-n-over-2.pdf">{n \choose n/2} example</a>, from Wednesday, February 5th, Week 1
	<li><a href="big-oh-with-limits.pdf">Big O notation and limits</a>
	<li><a href="http://en.wikipedia.org/wiki/Big_O_notation#Family_of_Bachmann.E2.80.93Landau_notations">Big O notation</a>, from Wikipedia</li>
	<li><a href="http://web.mit.edu/16.070/www/lecture/big_o.pdf">Big O notation notes, from 16.070</a></li>
	<li><strong>Code:</strong> <a href="https://github.com/alinush/6.006/blob/master/peak1d.py">1D peak finding, in Python</a>
<!--	<li>TODO: Add 2D peak finding code</li> -->
</ul>

<h3>Lecture 2: Python cost model, document distance</h3>
<ul>
	<li><a href="2014.02.06.w01-th-python-cost-model-lec02.pdf">Lecture 2 notes</a>, from Thursday, February 6th, Week 1
	<li><a href="http://cs.lmu.edu/~ray/notes/alganalysis/">Algorithm Analysis</a>, by Prof. Ray Toal</li>
<!--	<li>TODO: Add document distance code</li>-->
</ul>

<h3>Lecture 3: Insertion sort, merge sort, expanding recurrences into trees</h3>
<ul>
	<li>Romanian folk dancing: <a href="http://www.youtube.com/watch?v=ROalU379l3U">Insertion sort</a></li>
	<li>Transylvanian-Saxon (German) folk dancing: <a href="http://www.youtube.com/watch?v=XaqR3G_NVoo">Merge sort</a></li>
	<li><strong>Code:</strong> <a href="https://github.com/alinush/6.006/blob/master/insertion-sort.py">Insertion sort, in Python</a>
	<ul><li>Output of code <a href="https://github.com/alinush/6.006/blob/master/output/insertion-sort.txt">here</a>.</li></ul>
<!--	<li>TODO: Add insertion sort analysis of runtime in terms of number of inversions</li> -->
	<li><a href="http://en.wikipedia.org/wiki/Master_theorem">Master theorem</a>, from Wikipedia</li>
<!--	<li>TODO: Add merge sort code</li>
	<li>TODO: Add master theorem links and recursion tree examples</li>-->
</ul>

<h3>Lecture 4: Priority queues, heaps, heapify, heap-sort</h3>
<ul>
	<li><a href="http://www.cs.umd.edu/~meesh/351/mount/lectures/lect14-heapsort-analysis-part.pdf">Why building a heap takes linear time</a>, from Univ. of Maryland</li>
</ul>

<h3>Lecture 5: Binary search trees</h3>
<ul>
		<li><a href="http://webdocs.cs.ualberta.ca/~holte/T26/del-from-bst.html">Deleting a node from a BST</a>, from Univ. of Alberta</li>
</ul>

<h3>Lecture 6: AVL trees</h3>
<ul>
	<li>AVL tree simulator <a href="http://www.qmatica.com/DataStructures/Trees/AVL/AVLTree.html">here</a>. Watch insertions, deletions, traversals, etc. User controlled, step by step animations.</li>
	<li>Another AVL tree simulator <a href="http://www.cs.usfca.edu/~galles/visualization/AVLtree.html">here</a>.
	<li>AVL implementation in C++ <a href="https://github.com/alinush/avl-tree">here</a></li>
       <li><a href="avl-height-proof.pdf">Why are AVL trees \log{n} in height?</a></li>
</ul>

<h3>Lecture 7: Counting sort, radix sort, lower bounds on sorting</h3>
<ul>
	<li><a href="https://secs.ceas.uc.edu/~jpaul/472/lec15.html">Comparison or decision trees</a>, from Univ. of Cincinnati</li>
</ul>

<h3>Lecture 8: Hashing I: Python dictionaries, hash-tables with chaining, simple uniform hashing assumption</h3>

<h3>Lecture 9: Hashing II: Division method, multiplication method, amortized analysis of hash-table inserts, Rabin Karp string matching</h3>
<!-- TODO: add mersenne primes bit: http://ariya.blogspot.com/2007/02/modulus-with-mersenne-prime.html -->
<ul>
	<li><a href="rec09-amortized-analysis-and-rabin-karp.pdf">Recitation 9 notes</a> on amortized analysis and Rabin Karp</li>
	<li><a href="rec06-rabin-karp-spring2011.pdf">Recitation notes on Rabin Karp</a>, from 6.006 Spring 2011</li>
</ul>

<h3>Lecture 10: Hashing III: Open-addressing</h3>
<ul>
	<li><a href="http://webdocs.cs.ualberta.ca/~holte/T26/open-addr.html">Double hashing</a> examples with deletions (tricky), from Univ. of Alberta</li>
	<li><a href="rec10-open-addressing.pdf">Recitation 10 notes</a> on open-addressing and cryptographic hash functions</li>
	<li><a href="https://github.com/alinush/6.006/blob/master/pset3/set-using-dict.py">PSET3 Problem 3-1:</a> Set using an abstract dictionary</li>
	<li><a href="https://github.com/alinush/6.006/blob/master/pset3/matrices-rolling-hashes.py">PSET3 Problem 3-3:</a> Searching a matrix using rolling hashes</li>
</ul>

<h3>Lecture 11: Catalan numbers, Newton's method, Karatsuba multiplication</h3>
<ul>
	<li><a href="http://www.math.sc.edu/~howard/Classes/554b/catalan.pdf">Catalan numbers</a>, from Univ. of South Carolina</li>
	<li><a href="http://mathcircle.berkeley.edu/BMC6/pdf0607/catalan.pdf">Catalan numbers</a>, from Univ of California, 		Berkeley</li>
	<li><a href="http://www.ltcconline.net/greenl/courses/105/applications/NEWT.HTM">When does the Newton method fail?</a></li>
	<li><a href="http://en.wikipedia.org/wiki/Karatsuba_algorithm">Karatsuba multiplication</a>, from Wikipedia</li>
</ul>

<h3>Lecture 12: Using Newton's method to compute \sqrt(a)</h3>
<ul>
	<li><strong>Fun, fun:</strong> <a href="http://blog.quenta.org/2012/09/0x5f3759df.html">Quake 3's fast inverse square root explained</a>, by Christian Plesner Hansen</li>
</ul>

<h3>Lecture 13: Graphs, Breadth first search (BFS)</h3>
<!--<ul>
	<li></li>
</ul>-->

<h3>Lecture 14: Depth first search (DFS), topological sorting</h3>
<ul>
	<li><em>Reading:</em> Depth first search: edge and node classification, CLRS 3rd ed., pg. 603-612</li>
	<li><em>Reading:</em> Topological sorting using depth first search, CLRS 3rd ed., pg. 612-615</li>
</ul>

<h3>Lecture 15: Shortest paths, edge relaxation</h3>

<h3>Lecture 16: Dijkstra's shortest path algorithm</h3>
<ul>
	<li><a href="http://www.cse.ust.hk/~dekai/271/notes/L10/L10.pdf">Dijkstra lecture notes</a>, from The Hong Kong Univ. of Science and Technology</li>
</ul>

<h3>Lecture 17: Bellman-Ford shortest path algorithm</h3>
<ul>
	<li><a href="mit-fall-2010-bellman-ford.pdf">Recitation notes</a> from 6.006 Fall 2010</li>
</ul>

<h3>Lecture 18: Dijkstra optimizations (bidirectional search)</h3>

<h3>Quiz 2</h3>
<ul>
	<li>Previous years 6.006 materials <a href="http://courses.csail.mit.edu/6.006/">here</a></li>
	<li><b>Stuff to know:</b> open-addressed hash tables (linear probing, double hashing, uniform hashing assumption, etc.), numerics (Karatsuba, Newton approximations, etc.), graphs, Depth-first search, Breadth-first search, edge classification, shortest path algorithms, Dijkstra's algorithm, the Bellman-Ford algorithm</li>
</ul>

<h3>Lecture 19: Dynamic Programming I: Memoization, subproblems and dependencies, Fibonacci numbers, Coin Row problem, bottom-up DP</h3>
<!--<ul>
	<li></li>
</ul>-->

<h3>Lecture 20: Dynamic Programming II: Text justification</h3>
<ul>
	<li>Worked out <a href="http://www.cs.cornell.edu/courses/CS4820/2011sp/handouts/sample4.pdf">text justification</a>, from Cornell University</li>
	<li>Transcript of a lecture on <a href="http://users.csc.calpoly.edu/~grade_cstaley/cpe349/DPText/Transcript.html">text justification</a>, from Cal Poly</li>
</ul>

<h3>Lecture 21: Dynamic Programming III: Matrix chain multiplication, edit distance, knapsack</h3>
<ul>
	<li><em>Reading:</em> CLRS 3rd ed., Chapter 15 Dynamic programming, pg. 359-389</li>
	<li><em>Reading:</em> The Algorithm Design Manual, 2nd ed., Chapter 8 Dynamic programming, pg. 273-304</li>
	<li>Worked out <a href="mat-chain-mult.pdf">matrix chain multiplication</a></li>
</ul>

<h3>Lecture 22: Dynamic Programming IV</h3>
<ul>
	<li><a href="http://www.cs.uiuc.edu/~jeffe/teaching/algorithms/notes/05-dynprog.pdf">Practice problems</a>, from University of Illinois, at Urbana-Champaign
</ul>

<h3>Lecture 23: Computational complexity, P, NP, EXP, the halting problem, reductions</h3>
<ul>
	<li><strong>Fun, fun:</strong> Scott Aaronson's TED <a href="https://www.youtube.com/watch?v=SczraSQE3MY">talk</a></li>
</ul>

<!--<h3>Lecture : </h3>
<ul>
	<li></li>
</ul>-->

<h3>Appendix</h3>	
<ul>
	<li><a href="http://en.wikipedia.org/wiki/Geometric_series">Geometric series</a>, from Wikipedia</li>
	<li><a href="http://www.proofwiki.org/wiki/Change_of_Base_of_Logarithm">Change of base in logarithms</a>, from ProofWiki</li>
</ul>

</body>
</html>
